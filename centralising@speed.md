#Centralizing at speed
For several of the larger (commerce) platforms that we help build and support, we see that centralisation makes sense: Acquiring the required skills and best practices, building the platform.

With design in our DNA, we were curious how to keep an open view on and get input from a wide pool of customers. With different countries and brands involved, internal and external pressure on issues make this difficult. The main defining factor for us is the time it takes from idea to realisation in production.

How do these platforms retain and organise their agility? We interviewed several projects to see if there are emergent practices to minimise the time between feedback or idea inception and the release to production of the resulting improvement or solution. Especially for multi-country, multi-brand platform, this is not an easy task.

Taking the risk of stating the obvious, but speed is an essential element of agile development. Testing hypotheses cut a lot of internal discussion short, keeps stakeholders happy and helps keeping deployments small. It is much more than team velocity, because this is only a small part (albeit a costly one) of the total chain from idea to production. Drawing this chain can help visualise and improve this chain.

As eFocus is involved in several of these platforms, in various industries, sizes and maturity levels, it was easy to do a quick tour and gather the learnings of these platforms.

## What did we learn?

###Organisational design, but not for speed
For all platforms, the governance and organisation around it got quite some attention. Steering committees, project teams and PO structures were thought through and set up. All projects started with the defined structure in place. In some cases not for the full 100%, but this was resolved quickly.

Interesting observation was that none of the organisations took end to end speed as one of the factors for the setup. Governance, control, organisation and budget alignment, equal representation of stakeholders were mentioned. Most of the discussion during the initial phase grew organically and the team was setup according to existing standards and (corporate practices). In one instance, a best practice was adapated to specific needs for the platform. (The hybris best practices guide was used as a reference).

###Internal speed in first phase
Almost all platforms started building a form of MVP. (minimal viable product), a base or first level of the platform. Speed in this phase had an internal focus. One stakeholder or product owner took the lead during this phase and decided what the MVP would be and look like. This helped in getting a baseline live. The duration of this phase differed greatly
per platform. Where some MVP's took several months, others took a year or longer. Expectations of stakeholders were of course affected by this.

The deciding factors for this difference in time were mainly organisational and governance-related. Some steering committees and/or major stakeholders required the MVP to be exactly on par with the as-is situation or took the biggest country as the launch site. The MVP, in other words, was mainly internalised. Others chose to release to a small subset of customers, to a smaller brand, or to one country. One chose to release a basic version (accelerator version) to several countries.

Overall, 6 out of 10 chose to release before the platform was on-par with expectations or the existing platform. <<< checken>>>. None of the platforms went with a big bang for all brands and countries, which meant that there was a transition phase on going live.

###Feedback and cycle time
All platforms used an internal business testing and accepting phase. During this phase, adjustments were needed to porcesses and governance to incorporate the feedback. One team started using [Qtest](https://www.qasymphony.com/testing-platform/qtest-test-case-management/) to speed up the hand-over between user feedback and backlog setup. Others freed up the product owner, tester or information analyst to gather feedback and define backlog status.

After go-live all platforms adjusted to the new sources of feedback. This adjustment in governance was done in several ways and got less attention and focus than the initial setup, because of all the pressure during the go-live phase.

##Steering committees
Two of the platforms had no steering committee or one that was focused only on the overall budget. One of the platforms went so far as not to show the MVP internally before go-live. This helped keeping focus on the MVP and on getting it out as soon a possible. A third platform did internal demo's, but only after validation by end-users. Combining the feedback with the demo helped keeping the internal discussion in check.

##What will we do?
During the initiation phases of new platforms, we will press the issue of speed in the overall governance. First idea is to create a value chain analysis and follow an idea or story during the MVP phase and during the operations phase. A nice, hands-on example is found [here](https://www.mindtools.com/pages/article/newTMC_10.htm).

We will also incorporate [Conway's law](https://en.wikipedia.org/wiki/Conway%27s_law) into the discussion: As you design the project organisation, this will affect the resulting platform. Conway  states that the (interface) structure of a software system will reflect the organisational structure. “The structure of a problem reflects the structure of the organization that created it.” Bill Corcoran’s version of Conway’s Law.

Furthermore, we will try to coin the term feedback committee (comprising of users) in stead of steering committee, whih are by definition more internally focused.

We're curious on your views, experiences and suggestions!

###Disclaimer:
The basis was an in-depth interview on several (10) larger platform. All had the characteristics that they were multi-brand and multi-country and eFocus was involved in development and/or operations.
